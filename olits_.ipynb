{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ox7E10OqUBqR"
   },
   "source": [
    "The goal of this project is :\n",
    " - Identify main reason for customer satisfaction or dissatisfaction\n",
    " - Predict satisfaction level by category and product type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n",
      "[nltk_data] Error loading rslp: <urlopen error [Errno 8] nodename nor\n",
      "[nltk_data]     servname provided, or not known>\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aaddde49867f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhrases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('rslp')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "#import string\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "from gensim import corpora\n",
    "from gensim.models import Phrases\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('brazilian-ecommerce/olist_order_reviews_dataset.csv', header=1 )\n",
    "reviews\n",
    "reviews.review_comment_title = reviews.review_comment_title.fillna('')\n",
    "reviews.review_comment_message = reviews.review_comment_message.fillna('')\n",
    "reviews[\"review_comment\"] = reviews['review_comment_title'].map(str) + ' ' + reviews['review_comment_message'].map(str)\n",
    "reviews['review_comment'] = reviews['review_comment'].apply(lambda x: ' '.join(pd.unique(x.split())))\n",
    "#reviews_only = reviews[pd.notnull(reviews['review_comment'])]\n",
    "reviews.head()\n",
    "reviews = reviews[pd.notnull(reviews['review_comment_title']) | pd.notnull(reviews['review_comment_message'])]\n",
    "reviews['review_comment']  = reviews['review_comment'] .str.replace('[^\\w\\s]','')\n",
    "reviews['review_comment']  = reviews['review_comment'].str.lower()\n",
    "reviews.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "#stopwords = set(stopwords) - set(('não'))\n",
    "#noise_words = ['recebemo', 'recebimento', 'nan','produto','correio', 'entregu','recomendo','compra', 'comprar','recebi', 'compra', 'entregu', 'entrega', 'entregoa', 'comprei',  'veio', 'é', 'pedido' , 'chegou', 'apena']\n",
    "#recebemo\" + 0.009*\"funciona\" + 0.009*\"recebimento\"\n",
    "#\" + 0.025*\"veio\" + 0.024*\"é\" + 0.017*\"entregu\" + 0.013*\"pedido\" + 0.013*\"chegou\" + 0.011*\"apena\" + 0.011*\"qualidad\" + 0.010*\"recomendo\"\n",
    "\n",
    "\n",
    "\n",
    "reviews['review_comment_t']  = reviews['review_comment'] .str.replace('[^\\w\\s]','')\n",
    "reviews['review_comment_t']  = reviews['review_comment_t'] .str.lower().str.split()\n",
    "#reviews['review_comment_t'] =  reviews['review_comment_t'].apply(lambda x: [item for item in x if item not in stopwords ])\n",
    "\n",
    "#reviews['review_comment_t'] =  reviews['review_comment_t'].apply(lambda x: [item for item in x if item not in noise_words ])\n",
    "\n",
    "reviews['review_comment_t_stem'] = reviews['review_comment_t'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "reviews[reviews['review_score']<3][['review_comment','review_comment_t']].head()\n",
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['review_pos_neg'] = reviews['review_score'] \n",
    "reviews.head()\n",
    "\n",
    "#reviews_only['review_pos_neg'] ([0, 1, 2, 3, 4, 5], ['neg', 'neg', 'neg', 'neg', 'pos', 'pos'])\n",
    "reviews['review_pos_neg'] = reviews['review_pos_neg'].map({1: 'neg', 2: 'neg', 3: 'neg', 4: 'neg', 5:'pos' })\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = reviews[['review_comment_t_stem', 'review_pos_neg']]\n",
    "df.apply(tuple, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum = []\n",
    "for wlist in reviews['review_comment_t_stem']:\n",
    "  sum = sum + wlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mergedlist = list(sum)\n",
    "documents = [tuple(x) for x in df.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(mergedlist)\n",
    "word_features = list(all_words)[:600]\n",
    "word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print('Accuracy: ', nltk.classify.accuracy(classifier, test_set))\n",
    "print(classifier)\n",
    "print(classifier.show_most_informative_features(400))\n",
    "print(classifier.most_informative_features(400))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using exploratory sentiment analysis revieled few main reson for satisfaction/dissatisfaction: \n",
    "- Quality of a product(s) - senatnces describing color, size, diemntions, aesthetic qualities inducate that review is about quality, it could be both positive and negative.  \n",
    "- Quantity of product(s) - lack of full order. Mostly in negative tone, this reviews are ususlly complaints about the difference between the number of products aht was ordered and teh number of products that was delivered.\n",
    "- Delivery - There are a lot of verbs describing delivery , verb  'delivered' (entregue) and others may not signify any connotation and may appear in othe contexts. And there adverbes that refer to timing that actually means that the comment is about the delivery.\n",
    "- Costumer service - there are some verbs that may refer to costmer servis: email, phone.\n",
    "\n",
    "While this sentiment analysis may show how strong a word is associated with the reason for satisfaction or dissaisfaction with an order.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to process review data was labeled, manual lableing revieled more resons, some of them more common: product was not delivered at all, and some of them are less common, i.e. wrong item. Costumer service category proved to be an uncommun complaint too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quality_i = [\"defeito\", 'menor','branca','quebrado', 'diferente', 'foto', \"descrição\",'falso', 'falsificado','condiz', 'riscos', 'proteção','danificado']\n",
    "delivery_i = [\"rapido\", 'antes','depois', 'prazo de entrega', 'riscos', 'proteção','danificado']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('brazilian-ecommerce/olist_order_reviews_dataset.csv', header=1 )\n",
    "reviews\n",
    "reviews.review_comment_title = reviews.review_comment_title.fillna('')\n",
    "reviews.review_comment_message = reviews.review_comment_message.fillna('')\n",
    "reviews[\"review_comment\"] = reviews['review_comment_title'].map(str) + ' ' + reviews['review_comment_message'].map(str)\n",
    "reviews['review_comment'] = reviews['review_comment'].apply(lambda x: ' '.join(pd.unique(x.split())))\n",
    "reviews.head()\n",
    "reviews = reviews[pd.notnull(reviews['review_comment_title']) | pd.notnull(reviews['review_comment_message'])]\n",
    "reviews['review_comment']  = reviews['review_comment'] .str.replace('[^\\w\\s]','')\n",
    "reviews['review_comment']  = reviews['review_comment'].str.lower()\n",
    "reviews.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(reviews.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimention reduction algorithm may pca ica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "randomly selected fields were labeled :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_480 = pd.read_csv('brazilian-ecommerce/olist_order_reviews_dataset_manual_review_480__.csv', encoding=\"cp1252\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_480.review_comment_title = reviews_480.review_comment_title.fillna('')\n",
    "reviews_480.review_comment_message = reviews_480.review_comment_message.fillna('')\n",
    "reviews_480[\"review_comment\"] = reviews_480['review_comment_title'].map(str) + ' ' + reviews_480['review_comment_message'].map(str)\n",
    "reviews_480['review_comment'] = reviews_480['review_comment'].apply(lambda x: ' '.join(pd.unique(x.split())))\n",
    "#reviews_only = reviews[pd.notnull(reviews['review_comment'])]\n",
    "reviews_480.head()\n",
    "reviews_480 = reviews_480[pd.notnull(reviews_480['review_comment_title']) | pd.notnull(reviews_480['review_comment_message'])]\n",
    "reviews_480['review_comment']  = reviews_480['review_comment'] .str.replace('[^\\w\\s]','')\n",
    "reviews_480['review_comment']  = reviews_480['review_comment'].str.lower()\n",
    "reviews_480.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(reviews_480.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_480\n",
    "reviews_480[['delivery_pos',\n",
    " 'quality_pos',\n",
    " 'quantity_pos',\n",
    " 'cs_pos',\n",
    " 'price_pos',\n",
    " 'delivery',\n",
    " 'delivery_not_del',\n",
    " 'quality',\n",
    " 'quantity_parcial',\n",
    " 'wrong_item',\n",
    " 'cs']] = reviews_480[['delivery_pos',\n",
    " 'quality_pos',\n",
    " 'quantity_pos',\n",
    " 'cs_pos',\n",
    " 'price_pos',\n",
    " 'delivery',\n",
    " 'delivery_not_del',\n",
    " 'quality',\n",
    " 'quantity_parcial',\n",
    " 'wrong_item',\n",
    " 'cs']].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reviews_480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_480"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fvk_gIeirJYr"
   },
   "source": [
    "#Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsm = pd.read_csv('brazilian-ecommerce/olist_order_reviews_dataset_manual_review_.csv')\n",
    "reviews = pd.read_csv('brazilian-ecommerce/olist_order_reviews_dataset.csv')\n",
    "#reviewsm = reviewsm [['review_id',\t'delivery_pos',\t'quality_pos', \t'quantity_pos',\t'cs_pos'\t,'price_pos']]\n",
    "\n",
    "\n",
    "reviewsm.review_comment_title = reviewsm.review_comment_title.fillna('')\n",
    "reviewsm.review_comment_message = reviewsm.review_comment_message.fillna('')\n",
    "\n",
    "reviewsm[\"review_comment\"] = reviewsm['review_comment_title'].map(str) + ' ' + reviewsm['review_comment_message'].map(str)\n",
    "reviewsm['review_comment'] = reviewsm['review_comment'].apply(lambda x: ' '.join(pd.unique(x.split())))\n",
    "\n",
    "#reviews_only = reviews[pd.notnull(reviews['review_comment'])]\n",
    "\n",
    "reviewsm = reviewsm[pd.notnull(reviewsm['review_comment_title']) | pd.notnull(reviewsm['review_comment_message'])]\n",
    "\n",
    "reviewsm['review_comment']  = reviewsm['review_comment'] .str.replace('[^\\w\\s]','')\n",
    "reviewsm['review_comment']  = reviewsm['review_comment'] .str.lower()\n",
    "\n",
    "\n",
    "\n",
    "reviewsm_pos = reviewsm[pd.notnull(reviewsm['delivery_pos']) & pd.notnull(reviewsm['quality_pos']) & pd.notnull(reviewsm['quantity_pos']) &  pd.notnull(reviewsm['cs_pos'])& pd.notnull(reviewsm['price_pos'])\n",
    "                   #|pd.notnull(reviewsm['delivery']) | pd.notnull(reviewsm['delivery_not_del'])| pd.notnull(reviewsm['quality'])| \n",
    "               # pd.notnull(reviewsm['quantity/parcial'])| pd.notnull(reviewsm['wrong_item'])| pd.notnull(reviewsm['cs'])\n",
    "                   ]\n",
    "\n",
    "\n",
    "reviewsm_pos_n = reviewsm[(pd.notnull(reviewsm['delivery_pos']) & pd.notnull(reviewsm['quality_pos']) & pd.notnull(reviewsm['quantity_pos']) &  pd.notnull(reviewsm['cs_pos'])& pd.notnull(reviewsm['price_pos']))\n",
    "                 |  (pd.notnull(reviewsm['delivery']) & pd.notnull(reviewsm['delivery_not_del'])& pd.notnull(reviewsm['quality'])& \n",
    "               pd.notnull(reviewsm['quantity_parcial'])& pd.notnull(reviewsm['wrong_item'])& pd.notnull(reviewsm['cs'])\n",
    "                   )]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#len(reviewsm.dropna())\n",
    "#reviewsm.head()\n",
    "#reviewsm = reviewsm.dropna()\n",
    "#reviewsm_ = pd.merge(reviews, reviews, left_on='review_id')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reviewsm_pos_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviewsm_pos_n_c = reviewsm_pos_n.append(reviews_480) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsm_pos_n_c\n",
    "len(reviewsm_pos_n_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviewsm_pos_n=reviewsm_pos_n_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsm_pos_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsm_pos_n.loc[reviewsm_pos_n.delivery_pos >= 1, 'delivery_categories'] = 'positive' \n",
    "reviewsm_pos_n.loc[reviewsm_pos_n.delivery >=1, 'delivery_categories'] = 'negative' \n",
    "reviewsm_pos_n.loc[reviewsm_pos_n.delivery_not_del >=1, 'delivery_categories'] = 'negative' \n",
    "\n",
    "\n",
    "reviewsm_pos_n.loc[reviewsm_pos_n.quality_pos >= 1, 'quality_categories'] = 'positive' \n",
    "reviewsm_pos_n.loc[reviewsm_pos_n.quality >=1, 'quality_categories'] = 'negative' \n",
    "\n",
    "\n",
    "\n",
    "reviewsm_pos_n.loc[reviewsm_pos_n.quantity_pos >= 1, 'quantity_categories'] = 'positive' \n",
    "reviewsm_pos_n.loc[reviewsm_pos_n.quantity_parcial >=1, 'quantity_categories'] = 'negative' \n",
    "\n",
    "reviewsm_pos_n.loc[reviewsm_pos_n.wrong_item >=1, 'quantity_categories'] = 'negative' \n",
    "\n",
    "\n",
    "\n",
    "reviewsm_pos_n.loc[reviewsm_pos_n.wrong_item >= 1, 'wrong_item_categories'] = 'negative' \n",
    "\n",
    "reviewsm_pos_n.loc[reviewsm_pos_n.quantity_pos >=1, 'quant_wrong_categories'] = 'negative' \n",
    "\n",
    "\n",
    "\n",
    "reviewsm_pos_n.loc[reviewsm_pos_n.wrong_item >= 1, 'quant_wrong_categories'] = 'negative' \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#reviewsm_pos_n.loc[reviewsm_pos_n.delivery_not_del <1 & reviewsm_pos_n.delivery <1 & reviewsm_pos_n.delivery_pos < 1, 'delivery_categories'] = 'no_mention' \n",
    "\n",
    "reviewsm_pos_n['delivery_categories'] = reviewsm_pos_n['delivery_categories'].fillna('no_mention')\n",
    "reviewsm_pos_n['quality_categories'] = reviewsm_pos_n['quality_categories'].fillna('no_mention')\n",
    "\n",
    "reviewsm_pos_n['quantity_categories'] = reviewsm_pos_n['quantity_categories'].fillna('no_mention')\n",
    "\n",
    "\n",
    "reviewsm_pos_n['wrong_item_categories'] = reviewsm_pos_n['wrong_item_categories'].fillna('no_mention')\n",
    "\n",
    "\n",
    "reviewsm_pos_n['quant_wrong_categories'] = reviewsm_pos_n['quant_wrong_categories'].fillna('no_mention')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reviewsm_pos.head()\n",
    "\n",
    "\n",
    "reviewsm_pos_n\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reviewsm_pos_n.iloc[:729])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsm_pos_n_f = reviewsm_pos_n.iloc[:729]\n",
    "reviewsm_pos_n_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviewsm_pos_n = reviewsm_pos_n_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization for categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.subplot(2, 4, 1)\n",
    "s = pd.Series(reviewsm_pos_n.delivery_categories)\n",
    "s = s.value_counts(normalize=True)\n",
    "s.plot.bar()\n",
    "plt.title(r'delivery_categories')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(2, 4, 3)\n",
    "s = pd.Series(reviewsm_pos_n.wrong_item_categories)\n",
    "s = s.value_counts(normalize=True)\n",
    "s.plot.bar()\n",
    "plt.title(r'wrong_item_categories')\n",
    "\n",
    "plt.subplot(2, 4, 6)\n",
    "s = pd.Series(reviewsm_pos_n.quality_categories)\n",
    "s = s.value_counts(normalize=True)\n",
    "s.plot.bar()\n",
    "plt.title(r'quality_categories')\n",
    "\n",
    "plt.subplot(2, 4, 8)\n",
    "plt.title(r'quantity_categories')\n",
    "s = pd.Series(reviewsm_pos_n.quantity_categories)\n",
    "s = s.value_counts(normalize=True)\n",
    "s.plot.bar()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('delivery_categories\\n',reviewsm_pos_n.delivery_categories.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('wrong_item_categories\\n',reviewsm_pos_n.wrong_item_categories.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('quality_categories\\n',reviewsm_pos_n.quality_categories.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('quantity_categories\\n',reviewsm_pos_n.quantity_categories.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviewsm_pos_n.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 3), stop_words='english')\n",
    "features = tfidf.fit_transform(reviewsm_pos_n.review_comment).toarray()\n",
    "labels = reviewsm_pos_n.delivery_categories\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsm_chi2= reviewsm_pos_n\n",
    "list(reviewsm_chi2.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsm_chi2= reviewsm_pos_n\n",
    "reviewsm_chi2\n",
    "reviews['review_pos_neg'] = reviews['review_pos_neg'].map({1: 'neg', 2: 'neg', 3: 'neg', 4: 'neg', 5:'pos' })\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "N = 2\n",
    "for delivery_, delivery_categories in sorted(reviewsm_pos_n.items()):\n",
    "  features_chi2 = chi2(features, labels == delivery_categories)\n",
    "  indices = np.argsort(features_chi2[0])\n",
    "  feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "  trigrams = [v for v in feature_names if len(v.split(' ')) == 3]\n",
    "  print(\"# '{}':\".format(delivery_))\n",
    "  print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
    "  print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))\n",
    "  print(\"  . Most correlated trigrams:\\n. {}\".format('\\n. '.join(trigrams[-N:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "N = 2\n",
    "for delivery_, quality_categories in sorted(reviewsm_pos_n.items()):\n",
    "  features_chi2 = chi2(features, labels == delivery_categories)\n",
    "  indices = np.argsort(features_chi2[0])\n",
    "  feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "  trigrams = [v for v in feature_names if len(v.split(' ')) == 3]\n",
    "  print(\"# '{}':\".format(delivery_))\n",
    "  print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
    "  print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))\n",
    "  print(\"  . Most correlated trigrams:\\n. {}\".format('\\n. '.join(trigrams[-N:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print('Accuracy: ', nltk.classify.accuracy(classifier, test_set))\n",
    "print(classifier)\n",
    "print(classifier.show_most_informative_features(400))\n",
    "print(classifier.most_informative_features(400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delivery_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 3), stop_words='english')\n",
    "features = tfidf.fit_transform(reviewsm_pos_n.review_comment).toarray()\n",
    "labels = reviewsm_pos_n.delivery_categories\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviewsm_pos_n['review_comment'], reviewsm_pos_n['delivery_categories'], random_state = 0)\n",
    "count_vect = CountVectorizer(ngram_range=(1, 3))\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "  model_name = model.__class__.__name__\n",
    "  accuracies = cross_val_score(model, features, labels, scoring='f1_weighted', cv=CV)\n",
    "  for fold_idx, accuracy in enumerate(accuracies):\n",
    "    entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "import seaborn as sns\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_df.groupby('model_name').accuracy.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mod_select(cat):\n",
    "    tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 3), stop_words='english')\n",
    "    features = tfidf.fit_transform(reviewsm_pos_n.review_comment).toarray()\n",
    "    labels = reviewsm_pos_n[cat]\n",
    "    features.shape\n",
    "    \n",
    "   \n",
    "    models = [\n",
    "        RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "        LinearSVC(),\n",
    "        SVC(C = 700, gamma = 0.001, kernel = 'rbf' ),\n",
    "        MultinomialNB(),\n",
    "        LogisticRegression(random_state=0),\n",
    "    ]\n",
    "    CV = 5\n",
    "    cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "    entries = []\n",
    "    for model in models:\n",
    "      model_name = model.__class__.__name__\n",
    "      accuracies = cross_val_score(model, features, labels, scoring='f1_weighted', cv=CV)\n",
    "      for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "    cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "    import seaborn as sns\n",
    "    sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "    sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "                  size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "    plt.show()\n",
    "    \n",
    "    print(cv_df.groupby('model_name').accuracy.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_select('delivery_categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 3), stop_words='english')\n",
    "features = tfidf.fit_transform(reviewsm_pos_n.review_comment).toarray()\n",
    "labels = reviewsm_pos_n['delivery_categories']\n",
    "\n",
    "\n",
    "model  = SVC(C=700, gamma =0.001, degree = 0, kernel='rbf')\n",
    "model.fit(features, labels)\n",
    "reviews['predicted_delivery'] = model.predict(tfidf.transform( reviews['review_comment']).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['predicted_delivery'] = model.predict(tfidf.transform( reviews['review_comment']).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000, 1100], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 200, 300, 500, 600, 700, 740, 800, 900, 1000, 1100], 'gamma': [0.01, 0.0008, 0.001, 0.002, 0.0001],  'kernel': ['rbf']},\n",
    "  #{'C': [1, 10, 100, 1000, 1100], 'gamma': [0.01, 0.001, 0.0001], 'degree' : [0, 1, 2, 3, 4, 5, 6], 'kernel': ['poly']},\n",
    "    \n",
    " ]\n",
    "\n",
    "# Instantiate the logistic regression classifier: logreg\n",
    "svc = SVC()\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "svc_cv = GridSearchCV(svc, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the training data\n",
    "svc_cv.fit(features, labels)\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned svc Parameter: {}\".format(svc_cv.best_params_))\n",
    "print(\"Tuned svc Accuracy: {}\".format(svc_cv.best_score_))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_select('quality_categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 3), stop_words='english')\n",
    "features = tfidf.fit_transform(reviewsm_pos_n.review_comment).toarray()\n",
    "labels = reviewsm_pos_n['quality_categories']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000, 1100], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 700, 900, 1000, 1100], 'gamma': [0.01,  0.001,  0.0001],  'kernel': ['rbf']},\n",
    "  #{'C': [1, 10, 100, 1000, 1100], 'gamma': [0.01, 0.001, 0.0001], 'degree' : [0, 1, 2, 3, 4, 5, 6], 'kernel': ['poly']},\n",
    "    \n",
    " ]\n",
    "\n",
    "# Instantiate the logistic regression classifier: logreg\n",
    "svc = SVC()\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "svc_cv = GridSearchCV(svc, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the training data\n",
    "svc_cv.fit(features, labels)\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned svc Parameter: {}\".format(svc_cv.best_params_))\n",
    "print(\"Tuned svc Accuracy: {}\".format(svc_cv.best_score_))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model  = SVC(C=700, gamma =0.001, degree = 0, kernel='rbf')\n",
    "model.fit(features, labels)\n",
    "reviews['predicted_quality'] = model.predict(tfidf.transform( reviews['review_comment']).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_select('quantity_categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 3), stop_words='english')\n",
    "features = tfidf.fit_transform(reviewsm_pos_n.review_comment).toarray()\n",
    "labels = reviewsm_pos_n['quantity_categories']\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000, 1100], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 200, 300, 500, 600, 700, 740, 800, 900, 1000, 1100], 'gamma': [0.01, 0.0008, 0.001, 0.002,  0.003 , 0.0001],  'kernel': ['rbf']},\n",
    "  #{'C': [1, 10, 100, 1000, 1100], 'gamma': [0.01, 0.001, 0.0001], 'degree' : [0, 1, 2, 3, 4, 5, 6], 'kernel': ['poly']},\n",
    "    \n",
    " ]\n",
    "\n",
    "# Instantiate the logistic regression classifier: logreg\n",
    "svc = SVC()\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "svc_cv = GridSearchCV(svc, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the training data\n",
    "svc_cv.fit(features, labels)\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned svc Parameter: {}\".format(svc_cv.best_params_))\n",
    "print(\"Tuned svc Accuracy: {}\".format(svc_cv.best_score_))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 3), stop_words='english')\n",
    "features = tfidf.fit_transform(reviewsm_pos_n.review_comment).toarray()\n",
    "labels = reviewsm_pos_n['quantity_categories']\n",
    "\n",
    "\n",
    "model  = SVC(C=700, gamma =0.002, degree = 0, kernel='rbf')\n",
    "model.fit(features, labels)\n",
    "reviews['predicted_quantity'] = model.predict(tfidf.transform( reviews['review_comment']).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "nEfF6E3OxQiP",
    "outputId": "735f1861-8e71-4658-f2e3-d9a0a785dbd6"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "#stopwords = set(stopwords) - set(('não'))\n",
    "#noise_words = ['recebemo', 'recebimento', 'nan','produto','correio', 'entregu','recomendo','compra', 'comprar','recebi', 'compra', 'entregu', 'entrega', 'entregoa', 'comprei',  'veio', 'é', 'pedido' , 'chegou', 'apena']\n",
    "#recebemo\" + 0.009*\"funciona\" + 0.009*\"recebimento\"\n",
    "#\" + 0.025*\"veio\" + 0.024*\"é\" + 0.017*\"entregu\" + 0.013*\"pedido\" + 0.013*\"chegou\" + 0.011*\"apena\" + 0.011*\"qualidad\" + 0.010*\"recomendo\"\n",
    "\n",
    "\n",
    "\n",
    "reviews['review_comment_t']  = reviews['review_comment'] .str.replace('[^\\w\\s]','')\n",
    "reviews['review_comment_t']  = reviews['review_comment_t'] .str.lower().str.split()\n",
    "#reviews['review_comment_t'] =  reviews['review_comment_t'].apply(lambda x: [item for item in x if item not in stopwords ])\n",
    "\n",
    "#reviews['review_comment_t'] =  reviews['review_comment_t'].apply(lambda x: [item for item in x if item not in noise_words ])\n",
    "\n",
    "reviews['review_comment_t_stem'] = reviews['review_comment_t'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "reviews[reviews['review_score']<3][['review_comment','review_comment_t']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs_pos)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs_pos]\n",
    "bow_corpus[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=4, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "QM73trkEVdhc"
   },
   "outputs": [],
   "source": [
    "#df = reviews_only[['review_comment_message', 'review_score']]\n",
    "\n",
    "#classification\n",
    "df = reviews[['review_comment_t_stem', 'review_pos_neg']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "s0Zrajou9PQP",
    "outputId": "4c6db603-d737-455d-eb41-c0d544761f79"
   },
   "outputs": [],
   "source": [
    "\n",
    "df.apply(tuple, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Gh-f6mjO9isl"
   },
   "outputs": [],
   "source": [
    "sum = []\n",
    "for wlist in reviews['review_comment_t_stem']:\n",
    "  sum = sum + wlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "d7fBhlSqVdmL"
   },
   "outputs": [],
   "source": [
    "#mergedlist = list(sum)\n",
    "documents = [tuple(x) for x in df.values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1NfO_rxi9sZS"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "all_words = nltk.FreqDist(sum)\n",
    "#word_features = list(all_words)[:600]\n",
    "print(type(dict(all_words).keys()))\n",
    "d=dict(all_words).copy().keys()\n",
    "word_features ={x for x in chain(dict(all_words).copy().keys()) if x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "NElyToS1N5vu"
   },
   "outputs": [],
   "source": [
    "#pd.options.display.max_colwidth = 1000\n",
    "#print(reviews[reviews['review_comment'].str.contains(\"atrás\")]['review_comment'].shape)\n",
    "#reviews[reviews['review_comment'].str.contains(\"atrás\")]['review_comment'].head(10)\n",
    "#mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hzGYgqAM8gzZ"
   },
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "#random.shuffle(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "P798h8FQKwYG"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#word_df = pd.DataFrame(word_features)\n",
    "#word_df.to_csv('out.csv', index=False, header=False)\n",
    "#files.download('out.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Rn7KNiF2N-1V"
   },
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4qMPUvlROCWz"
   },
   "outputs": [],
   "source": [
    "print('Accuracy: ', nltk.classify.accuracy(classifier, test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "PJF3i53qOJK7"
   },
   "outputs": [],
   "source": [
    "print(classifier)\n",
    "print(classifier.show_most_informative_features(400))\n",
    "print(classifier.most_informative_features(400))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CDLHbm4rxC8G"
   },
   "source": [
    "#Manual Check\n",
    "Checkig comments that may inducate a reason fora negative or positive review -  quality, quantity, delivery, packaging "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qcZJoLN3qkmO"
   },
   "source": [
    "#Feature Engineering \n",
    "Feature Construction: The manual construction of new features from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hJvhivWS9d2P"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import date\n",
    "o['order_purchase_timestamp']= pd.to_datetime(o['order_purchase_timestamp'])\n",
    "o['order_approved_at']= pd.to_datetime(o['order_approved_at'])\n",
    "o['order_delivered_carrier_date']= pd.to_datetime(o['order_delivered_carrier_date'])\n",
    "o['order_delivered_customer_date']= pd.to_datetime(o['order_delivered_customer_date'])\n",
    "o['order_estimated_delivery_date']= pd.to_datetime(o['order_estimated_delivery_date'])\n",
    "o['delivery_delta'] = o['order_delivered_customer_date'] - o['order_purchase_timestamp']\n",
    "o['delivery_delta'] = o['delivery_delta'] /np.timedelta64(1,'h')\n",
    "\n",
    "o['est_delta'] = o['order_estimated_delivery_date'] - o['order_purchase_timestamp']\n",
    "o['est_delta'] = o['est_delta'] /np.timedelta64(1,'h')\n",
    "\n",
    "o['delivery_est_delta'] = o['est_delta'] - o['delivery_delta'] \n",
    "o['delivery_est_delta'] = o['delivery_est_delta']\n",
    "print(o.describe())\n",
    "o.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQUa5kb7p_AB"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "from gensim import corpora\n",
    "from gensim.models import Phrases\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from ds_voc.text_processing import TextProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "vKdOpDZnqA2_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S1haKLhLDLxO"
   },
   "source": [
    "#Joining Data\n",
    "\n",
    "merging orders, product, payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0LneFmA9xdzd"
   },
   "outputs": [],
   "source": [
    "reviews = reviews[['review_id',\t'order_id','predicted_delivery',\t'predicted_quality',\t'predicted_quantity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BxrHaeoRgWfa"
   },
   "outputs": [],
   "source": [
    "#join oreder items data, oreder payment, oreder review, oreders dataset, product \n",
    "\n",
    "# oreders + order items \n",
    "\n",
    "\n",
    "reviews_only = reviews.dropna()\n",
    "reviews_only.head()\n",
    "result = pd.merge(o, o_i, how='outer', on=['order_id'])\n",
    "\n",
    "\n",
    "# add product information \n",
    "result = pd.merge(result, p, how='outer', on=['product_id'])\n",
    "#add reviews\n",
    "result = pd.merge(result, reviews_only, how='outer', on=['order_id'])\n",
    "#creating dummies var for categories\n",
    "result = pd.get_dummies(result, prefix='Category_', columns=['product_category_name'])\n",
    "\n",
    "# add payments \n",
    "result = pd.merge(result, payments, how='outer', on=['order_id'])\n",
    "\n",
    "result = pd.get_dummies(result, prefix='type', columns=['payment_type'])\n",
    "\n",
    "#result[['order_id', 'customer_id', 'product_id' , 'seller_id', 'order_item_id', 'review_score']]\n",
    "#result.drop(['order_purchase_timestamp','order_approved_at',\t'order_delivered_carrier_date',\t'order_delivered_customer_date',\t'order_estimated_delivery_date','shipping_limit_date'])\n",
    "result.head()\n",
    "\n",
    "#list(result.columns.values) #time, day product_description_lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SnXsV-FJx7Ax",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result['delivery'] = result['predicted_delivery'].map({'positive': 1 , 'negative':0})\n",
    "result['quality'] = result['predicted_quality'].map({'positive': 1 , 'negative':0})\n",
    "result['quantity'] = result['predicted_quantity'].map({'positive': 1 , 'negative':0})\n",
    "\n",
    "\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(result.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_XU1hPSaj-vi"
   },
   "outputs": [],
   "source": [
    "result = result.groupby('order_id').agg({\n",
    "                                        'delivery': 'max',\t\n",
    "                                        'quality': 'max',\t\n",
    "                                        'quantity':'max',                          \n",
    "                                        'price':'sum', \n",
    "                                        'product_photos_qty': 'min','product_photos_qty': 'max', 'product_photos_qty': 'sum', \n",
    "\n",
    "                                          'delivery_est_delta': 'max',\n",
    "                                          'est_delta':'max',\n",
    "                                           'delivery_delta':'max',                             \n",
    "                                \n",
    "                                        'freight_value': 'sum',\n",
    "                                         \n",
    "                               \n",
    "    \n",
    "                                'type_credit_card': 'sum',\n",
    "                                           'type_debit_card': 'sum',\n",
    "                                           'type_not_defined': 'sum',\n",
    "                                           'type_voucher': 'sum',\n",
    "                             'payment_sequential': 'max',\n",
    " 'payment_installments':'max',\n",
    " 'payment_value':'sum',\n",
    "                                                                        'Category__pet_shop': 'sum',\n",
    "                                                                        'Category__portateis_casa_forno_e_cafe': 'sum' ,\n",
    "                                                                        'Category__agro_industria_e_comercio': 'sum' ,\n",
    "                                                                        'Category__alimentos': 'sum' ,\n",
    "                                                                        'Category__alimentos_bebidas': 'sum' ,\n",
    "                                                                        'Category__artes': 'sum' ,\n",
    "                                                                        'Category__artes_e_artesanato': 'sum' ,\n",
    "                                                                        'Category__artigos_de_festas': 'sum' ,\n",
    "                                                                        'Category__artigos_de_natal': 'sum' ,\n",
    "                                                                        'Category__audio': 'sum' ,\n",
    "                                                                        'Category__automotivo': 'sum' ,\n",
    "                                                                        'Category__bebes': 'sum' ,\n",
    "                                                                        'Category__bebidas': 'sum' ,\n",
    "                                                                        'Category__beleza_saude': 'sum' ,\n",
    "                                                                        'Category__brinquedos': 'sum' ,\n",
    "                                                                        'Category__cama_mesa_banho': 'sum' ,\n",
    "                                                                        'Category__casa_conforto': 'sum' ,\n",
    "                                                                        'Category__casa_conforto_2': 'sum' ,\n",
    "                                                                        'Category__casa_construcao': 'sum' ,\n",
    "                                                                        'Category__cds_dvds_musicais': 'sum' ,\n",
    "                                                                        'Category__cine_foto': 'sum' ,\n",
    "                                                                        'Category__climatizacao': 'sum' ,\n",
    "                                                                        'Category__consoles_games': 'sum' ,\n",
    "                                                                        'Category__construcao_ferramentas_construcao': 'sum' ,\n",
    "                                                                        'Category__construcao_ferramentas_ferramentas': 'sum' ,\n",
    "                                                                        'Category__construcao_ferramentas_iluminacao': 'sum' ,\n",
    "                                                                        'Category__construcao_ferramentas_jardim': 'sum' ,\n",
    "                                                                        'Category__construcao_ferramentas_seguranca': 'sum' ,\n",
    "                                                                        'Category__cool_stuff': 'sum' ,\n",
    "                                                                        'Category__dvds_blu_ray': 'sum' ,\n",
    "                                                                        'Category__eletrodomesticos': 'sum' ,\n",
    "                                                                        'Category__eletrodomesticos_2': 'sum' ,\n",
    "                                                                        'Category__eletronicos': 'sum' ,\n",
    "                                                                        'Category__eletroportateis': 'sum' ,\n",
    "                                                                        'Category__esporte_lazer': 'sum' ,\n",
    "                                                                        'Category__fashion_bolsas_e_acessorios': 'sum' ,\n",
    "                                                                        'Category__fashion_calcados': 'sum' ,\n",
    "                                                                        'Category__fashion_esporte': 'sum' ,\n",
    "                                                                        'Category__fashion_roupa_feminina': 'sum' ,\n",
    "                                                                        'Category__fashion_roupa_infanto_juvenil': 'sum' ,\n",
    "                                                                        'Category__fashion_roupa_masculina': 'sum' ,\n",
    "                                                                        'Category__fashion_underwear_e_moda_praia': 'sum' ,\n",
    "                                                                        'Category__ferramentas_jardim': 'sum' ,\n",
    "                                                                        'Category__flores': 'sum' ,\n",
    "                                                                        'Category__fraldas_higiene': 'sum' ,\n",
    "                                                                        'Category__industria_comercio_e_negocios': 'sum' ,\n",
    "                                                                        'Category__informatica_acessorios': 'sum' ,\n",
    "                                                                        'Category__instrumentos_musicais': 'sum' ,\n",
    "                                                                        'Category__la_cuisine': 'sum' ,\n",
    "                                                                        'Category__livros_importados': 'sum' ,\n",
    "                                                                        'Category__livros_interesse_geral': 'sum' ,\n",
    "                                                                        'Category__livros_tecnicos': 'sum' ,\n",
    "                                                                        'Category__malas_acessorios': 'sum' ,\n",
    "                                                                        'Category__market_place': 'sum' ,\n",
    "                                                                        'Category__moveis_colchao_e_estofado': 'sum' ,\n",
    "                                                                        'Category__moveis_cozinha_area_de_servico_jantar_e_jardim': 'sum' ,\n",
    "                                                                        'Category__moveis_decoracao': 'sum' ,\n",
    "                                                                        'Category__moveis_escritorio': 'sum' ,\n",
    "                                                                        'Category__moveis_quarto': 'sum' ,\n",
    "                                                                        'Category__moveis_sala': 'sum' ,\n",
    "                                                                        'Category__musica': 'sum' ,\n",
    "                                                                        'Category__papelaria': 'sum' ,\n",
    "                                                                        'Category__pc_gamer': 'sum' ,\n",
    "                                                                        'Category__pcs': 'sum' ,\n",
    "                                                                        'Category__perfumaria': 'sum' ,\n",
    "                                                                        'Category__pet_shop': 'sum' ,\n",
    "                                                                        'Category__portateis_casa_forno_e_cafe': 'sum' ,\n",
    "                                                                        'Category__portateis_cozinha_e_preparadores_de_alimentos': 'sum' ,\n",
    "                                                                        'Category__relogios_presentes': 'sum' ,\n",
    "                                                                        'Category__seguros_e_servicos': 'sum' ,\n",
    "                                                                        'Category__sinalizacao_e_seguranca': 'sum' ,\n",
    "                                                                        'Category__tablets_impressao_imagem': 'sum' ,\n",
    "                                                                        'Category__telefonia': 'sum' ,\n",
    "                                                                        'Category__telefonia_fixa': 'sum' ,\n",
    "                                                                        'Category__utilidades_domesticas': 'sum' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_KxURZgtqV5"
   },
   "outputs": [],
   "source": [
    "result_d= result.drop(['quality',\n",
    " 'quantity'], axis=1)\n",
    "result_d =result_d.dropna()\n",
    "delivery = result_d['delivery']\n",
    "result_d= result_d.drop(['delivery'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_d, delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "        RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "        LinearSVC(),\n",
    "        SVC(C = 700, gamma = 0.001, kernel = 'rbf' ),\n",
    "        MultinomialNB(),\n",
    "        LogisticRegression(random_state=0),\n",
    "    ]\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, result_d, delivery, scoring='f1_weighted', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "import seaborn as sns\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "                  size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.show()\n",
    "    \n",
    "print(cv_df.groupby('model_name').accuracy.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wCS3Voqs-HD1"
   },
   "outputs": [],
   "source": [
    "model_list = [LogisticRegression(), LinearSVC(), RandomForestClassifier() , KNeighborsClassifier(), GaussianNB(), Perceptron() , SGDClassifier(), DecisionTreeClassifier()]\n",
    "for i in model_list:\n",
    "  model = i.fit(result_d, delivery)\n",
    "  print( type(i).__name__, 'Accuracy: ',  np.average(cross_val_score(i, result_d, delivery, scoring='f1_weighted', cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the logistic regression classifier: logreg\n",
    "logr = LogisticRegression()\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logr_cv = GridSearchCV(logr, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the training data\n",
    "logr_cv.fit(result_d, delivery)\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned logreg Parameter: {}\".format(logr_cv.best_params_))\n",
    "print(\"Tuned logreg Accuracy: {}\".format(logr_cv.best_score_))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr_cv.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = logr_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = logr_cv.best_estimator_\n",
    "coefficients = pd.concat([pd.DataFrame(result_d.columns),pd.DataFrame(np.transpose(logistic.coef_), columns=['coef'])], axis = 1)\n",
    "coefficients.sort_values(by=['coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients.to_csv('hey.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_q= result.drop(['delivery',\n",
    " 'quantity'], axis=1)\n",
    "result_q =result_q.dropna()\n",
    "quality = result_q['quality']\n",
    "result_q= result_q.drop(['quality'], axis=1)\n",
    "\n",
    "model_list = [LogisticRegression(), LinearSVC(), RandomForestClassifier() , KNeighborsClassifier(), GaussianNB(), Perceptron() , SGDClassifier(), DecisionTreeClassifier()]\n",
    "for i in model_list:\n",
    "  model = i.fit(result_q, quality)\n",
    "  print( type(i).__name__, 'Accuracy: ', np.average(cross_val_score(i, result_q, quality, scoring='f1_weighted', cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQ8GIB4EmPUs"
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import  RandomizedSearchCV \n",
    "\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = RandomForestClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X, y)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randfor = tree_cv.best_estimator_\n",
    "coefficients_qual = pd.concat([pd.DataFrame(result_d.columns),pd.DataFrame(np.transpose(randfor.feature_importances_), columns=['feature_importances'])], axis = 1)\n",
    "coefficients_qual.sort_values(by=['feature_importances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "m_FENRyLk_-F"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8KO7WpJKvDUa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "oYTDpGeSmEZK"
   },
   "outputs": [],
   "source": [
    "result.head(2)\n",
    "result['order_id'].duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "JZIQn4AmmbR6"
   },
   "outputs": [],
   "source": [
    "#join oreder items data, oreder payment, oreder review, oreders dataset, product \n",
    "\n",
    "# oreders + order items \n",
    "result = pd.merge(o, o_i, how='outer', on=['order_id'])\n",
    "\n",
    "\n",
    "# add product information \n",
    "result = pd.merge(result, p, how='outer', on=['product_id'])\n",
    "#add reviews\n",
    "result = pd.merge(result, reviews_only, how='outer', on=['order_id'])\n",
    "#creating dummies var for categories\n",
    "result = pd.get_dummies(result, prefix='Category_', columns=['product_category_name'])\n",
    "# add payments \n",
    "result = pd.merge(result, payments, how='outer', on=['order_id'])\n",
    "\n",
    "\n",
    "#result[['order_id', 'customer_id', 'product_id' , 'seller_id', 'order_item_id', 'review_score']]\n",
    "result.drop(columns=['order_purchase_timestamp','order_approved_at',\t'order_delivered_carrier_date',\t'order_delivered_customer_date',\t'order_estimated_delivery_date','shipping_limit_date'])\n",
    "list(result.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "en4TFQvoXNP0"
   },
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4XT3JBlTXqDm"
   },
   "outputs": [],
   "source": [
    "#payments.order_id.loc['b81ef226f3fe1789b1e8b2acac839d17']\n",
    "result.loc[payments['order_id'] == '31bc09fdbd701a7a4f9b55b5955b8687']\n",
    "#payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "DgZaT_jbNgwQ"
   },
   "outputs": [],
   "source": [
    "payments['order_id'].duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "6b7WkSBkUlw6"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(result.order_id.nunique())\n",
    "print(result.customer_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rpohzAwpViA0"
   },
   "outputs": [],
   "source": [
    "print(o_i.order_id.nunique())\n",
    "print(o_i.customer_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "bPyc0La4mhIh"
   },
   "outputs": [],
   "source": [
    "s = pd.read_csv('olist_sellers_dataset.csv')\n",
    "print(s.info())\n",
    "print(s.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "tPvCBoEAm-FU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G-bI9cKDqvXk"
   },
   "source": [
    "#Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sFJ9x7vJWB1u"
   },
   "outputs": [],
   "source": [
    "payments = pd.read_csv('brazilian-ecommerce/olist_order_payments_dataset.csv')\n",
    "print(payments.describe())\n",
    "print(payments.info())\n",
    "print(payments.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59SNgsYmaCQc"
   },
   "outputs": [],
   "source": [
    "payments.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtfYxq0FbPYi"
   },
   "outputs": [],
   "source": [
    "o = pd.read_csv('brazilian-ecommerce/olist_orders_dataset.csv')\n",
    "print(o.info())\n",
    "print(o.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a3hb9QBteeSY"
   },
   "outputs": [],
   "source": [
    "o_i = pd.read_csv('brazilian-ecommerce/olist_order_items_dataset.csv')\n",
    "print(o_i.info())\n",
    "print(o_i.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nlVzPAKxc3MC"
   },
   "outputs": [],
   "source": [
    "category = pd.read_csv('brazilian-ecommerce/product_category_name_translation.csv')\n",
    "print(category.info())\n",
    "print(category.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "84JCL5ZBdJAO"
   },
   "outputs": [],
   "source": [
    "\n",
    "customers = pd.read_csv('brazilian-ecommerce/olist_customers_dataset.csv')\n",
    "print(customers.info())\n",
    "print(customers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6wZPV-4LhUnv"
   },
   "outputs": [],
   "source": [
    "geo = pd.read_csv('brazilian-ecommerce/olist_geolocation_dataset.csv')\n",
    "print(geo.info())\n",
    "print(geo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vmfn4rMTh1tK"
   },
   "outputs": [],
   "source": [
    "geo_s = pd.read_csv('brazilian-ecommerce/olist_sellers_dataset.csv')\n",
    "print(geo_s.info())\n",
    "print(geo_s.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pSjHRpVGllnZ"
   },
   "outputs": [],
   "source": [
    "p = pd.read_csv('brazilian-ecommerce/olist_products_dataset.csv')\n",
    "print(p.info())\n",
    "print(p.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "olits_.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
